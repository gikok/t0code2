{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/envs/z/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "#§from google.cloud import bigquery\n",
                "import os\n",
                "sa_account_file = 'bq_key.json'\n",
                "if os.path.isfile(sa_account_file) and not os.environ.get('GOOGLE_APPLICATION_CREDENTIALS'):\n",
                "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = sa_account_file\n",
                "\n",
                "\n",
                "pd.set_option(\"display.max_rows\", 320)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>searchKeyword</th>\n",
                            "      <th>searchCount</th>\n",
                            "      <th>ctr</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>wardrobe</td>\n",
                            "      <td>613283</td>\n",
                            "      <td>0.448881</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>desk</td>\n",
                            "      <td>568564</td>\n",
                            "      <td>0.445936</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>kallax</td>\n",
                            "      <td>416831</td>\n",
                            "      <td>0.556699</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>mirror</td>\n",
                            "      <td>334740</td>\n",
                            "      <td>0.410904</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>chest of drawers</td>\n",
                            "      <td>250499</td>\n",
                            "      <td>0.489558</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>995</th>\n",
                            "      <td>high chair baby</td>\n",
                            "      <td>4495</td>\n",
                            "      <td>0.517446</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>996</th>\n",
                            "      <td>kitchen chairs</td>\n",
                            "      <td>4491</td>\n",
                            "      <td>0.228295</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>997</th>\n",
                            "      <td>oven dish</td>\n",
                            "      <td>4487</td>\n",
                            "      <td>0.366569</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>998</th>\n",
                            "      <td>mammut</td>\n",
                            "      <td>4486</td>\n",
                            "      <td>0.492437</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>999</th>\n",
                            "      <td>glass bottle</td>\n",
                            "      <td>4478</td>\n",
                            "      <td>0.241815</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>1000 rows × 3 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        searchKeyword  searchCount       ctr\n",
                            "0            wardrobe       613283  0.448881\n",
                            "1                desk       568564  0.445936\n",
                            "2              kallax       416831  0.556699\n",
                            "3              mirror       334740  0.410904\n",
                            "4    chest of drawers       250499  0.489558\n",
                            "..                ...          ...       ...\n",
                            "995   high chair baby         4495  0.517446\n",
                            "996    kitchen chairs         4491  0.228295\n",
                            "997         oven dish         4487  0.366569\n",
                            "998            mammut         4486  0.492437\n",
                            "999      glass bottle         4478  0.241815\n",
                            "\n",
                            "[1000 rows x 3 columns]"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "r = bigquery.Client()\n",
                "q = \"\"\"\n",
                "SELECT * FROM `ingka-search-modelling-dev.search_data.top_10k_queries` LIMIT 1000\n",
                "\"\"\"\n",
                "r.query(q).to_dataframe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model and tokenizer loaded\n",
                        "Moved model to GPUs\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "Embedding(38136, 2048)"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_name = \"/home/gikok/output_001_old\"\n",
                "\n",
                "model3 = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "print(\"Model and tokenizer loaded\")\n",
                "\n",
                "model3.parallelize()\n",
                "print(\"Moved model to GPUs\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(Parameter containing:\n",
                            " tensor([[ 1.4355e-01,  3.8750e+00,  5.3516e-01,  ...,  3.0875e+01,\n",
                            "           1.3281e+00, -2.1500e+01],\n",
                            "         [-4.7812e+00,  7.3125e+00,  3.3438e+00,  ...,  1.0312e+01,\n",
                            "          -8.7109e-01, -1.3047e+00],\n",
                            "         [-4.9023e-01,  2.3906e+00, -5.1562e+00,  ..., -5.4297e-01,\n",
                            "           9.8750e+00, -1.3562e+01],\n",
                            "         ...,\n",
                            "         [-2.3773e-01, -4.4270e-01,  1.2582e+00,  ...,  1.7632e+00,\n",
                            "           9.7722e-01, -6.2005e-01],\n",
                            "         [-6.9064e-01, -1.8996e-02,  6.5908e-02,  ...,  1.0842e+00,\n",
                            "          -9.9326e-01,  1.2279e+00],\n",
                            "         [ 4.7744e-01,  8.7684e-01,  7.3150e-01,  ..., -9.7299e-01,\n",
                            "          -3.3360e-01, -2.1407e-01]], device='cuda:0', requires_grad=True),\n",
                            " Parameter containing:\n",
                            " tensor([[-0.0476, -0.0623, -0.0977,  ...,  0.0262,  0.0427, -0.0295],\n",
                            "         [-0.0674, -0.0129, -0.1523,  ..., -0.1436, -0.0286,  0.0645],\n",
                            "         [-0.0310, -0.1582,  0.2676,  ...,  0.0461, -0.0747,  0.1699],\n",
                            "         ...,\n",
                            "         [-0.0189,  0.0276,  0.0140,  ...,  0.0243,  0.0279,  0.0148],\n",
                            "         [-0.0119, -0.0059,  0.0364,  ..., -0.0065,  0.0172,  0.0007],\n",
                            "         [-0.0111,  0.0042,  0.0329,  ..., -0.0014, -0.0079,  0.0097]],\n",
                            "        device='cuda:0', requires_grad=True))"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "embeddings1, lm_head1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "A cow is a dairy animal that is bred for milk.\n"
                    ]
                }
            ],
            "source": [
                "inputs = tokenizer.encode(string, return_tensors=\"pt\")\n",
                "inputs = inputs.to(\"cuda:0\")\n",
                "with torch.no_grad():\n",
                "    print(tokenizer.decode(model.generate(inputs)[0], skip_special_tokens=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Is it a sex toy?\n"
                    ]
                }
            ],
            "source": [
                "inputs = tokenizer1.encode(\"99388356?\", return_tensors=\"pt\")\n",
                "inputs = inputs.to(\"cuda:0\")\n",
                "with torch.no_grad():\n",
                "    print(tokenizer1.decode(model1.generate(inputs)[0], skip_special_tokens=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'data' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_11254/392502954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
                    ]
                }
            ],
            "source": [
                "with torch.no_grad():\n",
                "    data1[0][1][:len(tokenizer),:]=torch.tensor(data[0][1][:len(tokenizer),:])\n",
                "    data1[-1][1][:len(tokenizer),:]=torch.tensor(data[-1][1][:len(tokenizer),:])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[32110,     1]], device='cuda:0')"
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "'best match'\n"
                    ]
                }
            ],
            "source": [
                "inputs = tokenizer1.encode(\"query: 'copper pans'\\nfor the query above, what item_no is the best match? '10364523' or '50451052'?\", return_tensors=\"pt\")\n",
                "inputs = inputs.to(\"cuda:0\")\n",
                "with torch.no_grad():\n",
                "    print(tokenizer1.decode(model1.generate(inputs)[0], skip_special_tokens=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Embedding(38136, 2048)"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "new = AutoModelForSeq2SeqLM.from_pretrained('bigscience/T0_3B')\n",
                "tokenizer = AutoTokenizer.from_pretrained('bigscience/T0_3B')\n",
                "\n",
                "# get all item_no and add as tokens\n",
                "items = pd.read_parquet(\"../training/data/item_no_6k.parquet.gzip\")[\"item_no\"].values.tolist()\n",
                "tokenizer.add_tokens(items)\n",
                "\n",
                "# then resize embeddings\n",
                "new.resize_token_embeddings(len(tokenizer))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Parameter containing:\n",
                            "tensor([[-0.0476, -0.0623, -0.0977,  ...,  0.0262,  0.0427, -0.0295],\n",
                            "        [-0.0674, -0.0129, -0.1523,  ..., -0.1436, -0.0286,  0.0645],\n",
                            "        [-0.0310, -0.1582,  0.2676,  ...,  0.0461, -0.0747,  0.1699],\n",
                            "        ...,\n",
                            "        [-0.0115,  0.0008,  0.0209,  ...,  0.0202, -0.0179,  0.0202],\n",
                            "        [ 0.0070,  0.0031,  0.0151,  ...,  0.0060, -0.0076,  0.0182],\n",
                            "        [-0.0079, -0.0044,  0.0043,  ..., -0.0190, -0.0053, -0.0022]],\n",
                            "       requires_grad=True)"
                        ]
                    },
                    "execution_count": 113,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "initial_lm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def norm_tensor(a):\n",
                "    a_n = torch.norm(a, p=2, dim=-1)\n",
                "    return a_n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "old values tensor(43.4352, grad_fn=<MinBackward1>) tensor(607.7497, grad_fn=<MaxBackward1>) tensor(71.4094, grad_fn=<StdBackward0>) tensor(410.8217, grad_fn=<MeanBackward0>) tensor(535.1478, grad_fn=<SqueezeBackward3>)\n",
                        "new values tensor(42.6671, grad_fn=<MinBackward1>) tensor(47.6193, grad_fn=<MaxBackward1>) tensor(0.7278, grad_fn=<StdBackward0>) tensor(45.2228, grad_fn=<MeanBackward0>) tensor(46.9068, grad_fn=<SqueezeBackward3>)\n"
                    ]
                }
            ],
            "source": [
                "items = 6036\n",
                "emb_old = norm_tensor(initial_emb[:-items,:])\n",
                "emb_new = norm_tensor(initial_emb[-items:,:])\n",
                "print(\"old values\", emb_old.min(), emb_old.max(), emb_old.std(), emb_old.mean(), emb_old.quantile(0.99))\n",
                "print(\"new values\", emb_new.min(), emb_new.max(), emb_new.std(), emb_new.mean(),  emb_new.quantile(0.99))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "old values tensor(43.4352, device='cuda:0', grad_fn=<MinBackward1>) tensor(607.7508, device='cuda:0', grad_fn=<MaxBackward1>) tensor(71.4094, device='cuda:0', grad_fn=<StdBackward0>) tensor(410.8224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(535.1484, device='cuda:0', grad_fn=<SqueezeBackward3>)\n",
                        "new values tensor(42.3666, device='cuda:0', grad_fn=<MinBackward1>) tensor(47.9816, device='cuda:0', grad_fn=<MaxBackward1>) tensor(0.7068, device='cuda:0', grad_fn=<StdBackward0>) tensor(45.2536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(46.9176, device='cuda:0', grad_fn=<SqueezeBackward3>)\n"
                    ]
                }
            ],
            "source": [
                "items = 6036\n",
                "emb_old = norm_tensor(embeddings[:-items,:])\n",
                "emb_new = norm_tensor(embeddings[-items:,:])\n",
                "print(\"old values\", emb_old.min(), emb_old.max(), emb_old.std(), emb_old.mean(), emb_old.quantile(0.99))\n",
                "print(\"new values\", emb_new.min(), emb_new.max(), emb_new.std(), emb_new.mean(),  emb_new.quantile(0.99))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "a spokesman for the british government said tuesday\n"
                    ]
                }
            ],
            "source": [
                "inputs = tokenizer1.encode(\"10364523\", return_tensors=\"pt\")\n",
                "inputs = inputs.to(\"cuda:0\")\n",
                "with torch.no_grad():\n",
                "    print(tokenizer1.decode(model1.generate(inputs)[0], skip_special_tokens=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "enc = model1.encoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[T5ForConditionalGeneration(\n",
                            "   (shared): Embedding(38136, 2048)\n",
                            "   (encoder): T5Stack(\n",
                            "     (embed_tokens): Embedding(38136, 2048)\n",
                            "     (block): ModuleList(\n",
                            "       (0): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (relative_attention_bias): Embedding(32, 32)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (1): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (2): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (3): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (4): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (5): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (6): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (7): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (8): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (9): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (10): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (11): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (12): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (13): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (14): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (15): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (16): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (17): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (18): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (19): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (20): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (21): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (22): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (23): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (final_layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (decoder): T5Stack(\n",
                            "     (embed_tokens): Embedding(38136, 2048)\n",
                            "     (block): ModuleList(\n",
                            "       (0): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (relative_attention_bias): Embedding(32, 32)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (1): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (2): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (3): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (4): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (5): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (6): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (7): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (8): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (9): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (10): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (11): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (12): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (13): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (14): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (15): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (16): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (17): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (18): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (19): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (20): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (21): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (22): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "       (23): T5Block(\n",
                            "         (layer): ModuleList(\n",
                            "           (0): T5LayerSelfAttention(\n",
                            "             (SelfAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (1): T5LayerCrossAttention(\n",
                            "             (EncDecAttention): T5Attention(\n",
                            "               (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "               (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "           (2): T5LayerFF(\n",
                            "             (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "               (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "               (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "               (dropout): Dropout(p=0.1, inplace=False)\n",
                            "               (gelu_act): NewGELUActivation()\n",
                            "             )\n",
                            "             (layer_norm): T5LayerNorm()\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           )\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (final_layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (lm_head): Linear(in_features=2048, out_features=38136, bias=False)\n",
                            " ),\n",
                            " Embedding(38136, 2048),\n",
                            " T5Stack(\n",
                            "   (embed_tokens): Embedding(38136, 2048)\n",
                            "   (block): ModuleList(\n",
                            "     (0): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (relative_attention_bias): Embedding(32, 32)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (1): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (2): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (3): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (4): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (5): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (6): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (7): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (8): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (9): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (10): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (11): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (12): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (13): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (14): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (15): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (16): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (17): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (18): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (19): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (20): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (21): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (22): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (23): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (final_layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (relative_attention_bias): Embedding(32, 32)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (1): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (2): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (3): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (4): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (5): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (6): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (7): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (8): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (9): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (10): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (11): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (12): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (13): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (14): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (15): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (16): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (17): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (18): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (19): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (20): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (21): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (22): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (23): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (relative_attention_bias): Embedding(32, 32)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (relative_attention_bias): Embedding(32, 32)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (relative_attention_bias): Embedding(32, 32)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (relative_attention_bias): Embedding(32, 32)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Embedding(32, 32),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " NewGELUActivation(),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Stack(\n",
                            "   (embed_tokens): Embedding(38136, 2048)\n",
                            "   (block): ModuleList(\n",
                            "     (0): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (relative_attention_bias): Embedding(32, 32)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (1): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (2): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (3): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (4): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (5): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (6): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (7): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (8): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (9): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (10): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (11): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (12): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (13): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (14): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (15): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (16): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (17): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (18): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (19): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (20): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (21): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (22): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "     (23): T5Block(\n",
                            "       (layer): ModuleList(\n",
                            "         (0): T5LayerSelfAttention(\n",
                            "           (SelfAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (1): T5LayerCrossAttention(\n",
                            "           (EncDecAttention): T5Attention(\n",
                            "             (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "             (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "         (2): T5LayerFF(\n",
                            "           (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "             (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "             (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "             (dropout): Dropout(p=0.1, inplace=False)\n",
                            "             (gelu_act): NewGELUActivation()\n",
                            "           )\n",
                            "           (layer_norm): T5LayerNorm()\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         )\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (final_layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (relative_attention_bias): Embedding(32, 32)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (1): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (2): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (3): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (4): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (5): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (6): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (7): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (8): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (9): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (10): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (11): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (12): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (13): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (14): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (15): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (16): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (17): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (18): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (19): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (20): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (21): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (22): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            "   (23): T5Block(\n",
                            "     (layer): ModuleList(\n",
                            "       (0): T5LayerSelfAttention(\n",
                            "         (SelfAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (1): T5LayerCrossAttention(\n",
                            "         (EncDecAttention): T5Attention(\n",
                            "           (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "           (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "       (2): T5LayerFF(\n",
                            "         (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "           (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "           (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "           (dropout): Dropout(p=0.1, inplace=False)\n",
                            "           (gelu_act): NewGELUActivation()\n",
                            "         )\n",
                            "         (layer_norm): T5LayerNorm()\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       )\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (relative_attention_bias): Embedding(32, 32)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (relative_attention_bias): Embedding(32, 32)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (relative_attention_bias): Embedding(32, 32)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (relative_attention_bias): Embedding(32, 32)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Embedding(32, 32),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerFF(\n",
                            "   (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "     (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "     (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     (gelu_act): NewGELUActivation()\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5DenseGatedGeluDense(\n",
                            "   (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "   (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   (gelu_act): NewGELUActivation()\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=2048, out_features=5120, bias=False),\n",
                            " Linear(in_features=5120, out_features=2048, bias=False),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5Block(\n",
                            "   (layer): ModuleList(\n",
                            "     (0): T5LayerSelfAttention(\n",
                            "       (SelfAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (1): T5LayerCrossAttention(\n",
                            "       (EncDecAttention): T5Attention(\n",
                            "         (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "         (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "     (2): T5LayerFF(\n",
                            "       (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "         (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "         (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "         (dropout): Dropout(p=0.1, inplace=False)\n",
                            "         (gelu_act): NewGELUActivation()\n",
                            "       )\n",
                            "       (layer_norm): T5LayerNorm()\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "     )\n",
                            "   )\n",
                            " ),\n",
                            " ModuleList(\n",
                            "   (0): T5LayerSelfAttention(\n",
                            "     (SelfAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (1): T5LayerCrossAttention(\n",
                            "     (EncDecAttention): T5Attention(\n",
                            "       (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "       (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            "   (2): T5LayerFF(\n",
                            "     (DenseReluDense): T5DenseGatedGeluDense(\n",
                            "       (wi_0): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wi_1): Linear(in_features=2048, out_features=5120, bias=False)\n",
                            "       (wo): Linear(in_features=5120, out_features=2048, bias=False)\n",
                            "       (dropout): Dropout(p=0.1, inplace=False)\n",
                            "       (gelu_act): NewGELUActivation()\n",
                            "     )\n",
                            "     (layer_norm): T5LayerNorm()\n",
                            "     (dropout): Dropout(p=0.1, inplace=False)\n",
                            "   )\n",
                            " ),\n",
                            " T5LayerSelfAttention(\n",
                            "   (SelfAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " T5Attention(\n",
                            "   (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            " ),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " Linear(in_features=2048, out_features=2048, bias=False),\n",
                            " T5LayerNorm(),\n",
                            " Dropout(p=0.1, inplace=False),\n",
                            " T5LayerCrossAttention(\n",
                            "   (EncDecAttention): T5Attention(\n",
                            "     (q): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (k): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "     (o): Linear(in_features=2048, out_features=2048, bias=False)\n",
                            "   )\n",
                            "   (layer_norm): T5LayerNorm()\n",
                            "   (dropout): Dropout(p=0.1, inplace=False)\n",
                            " ),\n",
                            " ...]"
                        ]
                    },
                    "execution_count": 82,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "list(model1.modules())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1 star no 1 star no 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
                    ]
                }
            ],
            "source": [
                "inputs = tokenizer1.encode(\"what is description of item_no 79399105?\", return_tensors=\"pt\")\n",
                "inputs = inputs.to(\"cuda:0\")\n",
                "with torch.no_grad():\n",
                "    print(tokenizer1.decode(model1.generate(inputs)[0], skip_special_tokens=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0\n",
                        "1\n",
                        "2\n",
                        "3\n",
                        "4\n",
                        "5\n",
                        "6\n",
                        "7\n",
                        "8\n",
                        "9\n",
                        "10\n",
                        "11\n",
                        "12\n",
                        "13\n",
                        "14\n",
                        "15\n",
                        "16\n",
                        "17\n",
                        "18\n",
                        "19\n",
                        "20\n",
                        "21\n",
                        "22\n",
                        "23\n",
                        "24\n",
                        "25\n",
                        "26\n",
                        "27\n",
                        "28\n",
                        "29\n",
                        "30\n",
                        "31\n",
                        "32\n",
                        "33\n",
                        "34\n",
                        "35\n",
                        "36\n",
                        "37\n",
                        "38\n",
                        "39\n",
                        "40\n",
                        "41\n",
                        "42\n",
                        "43\n",
                        "44\n",
                        "45\n",
                        "46\n",
                        "47\n",
                        "48\n",
                        "49\n",
                        "50\n",
                        "51\n",
                        "52\n",
                        "53\n",
                        "54\n",
                        "55\n",
                        "56\n",
                        "57\n",
                        "58\n",
                        "59\n",
                        "60\n",
                        "61\n",
                        "62\n",
                        "63\n",
                        "64\n",
                        "FINISHED\n"
                    ]
                }
            ],
            "source": [
                "##### 3 categories #####\n",
                "cats = \"\"\"item; room; service; other\"\"\"\n",
                "dic = {\"option1\": \"product_type\", \"option2\": \"room\", \"option3\": \"service\"}\n",
                "df = pd.read_csv('my_list.csv')\n",
                "i = 0\n",
                "while i < 65:\n",
                "    inp = [f\"Query: {search}. Which category does it belong to?\" +\n",
                "           cats for search in df.iloc[i:i+5, 1]]\n",
                "    inputs = tokenizer.batch_encode_plus(\n",
                "        inp, return_tensors='pt', padding=True)\n",
                "    inputs = inputs.to(\"cuda:0\")\n",
                "    with torch.no_grad():\n",
                "        for j in range(len(inp)):\n",
                "            print(i+j)\n",
                "            outputs = model.generate(inputs['input_ids'])\n",
                "            #if df.iloc[i+j,4] != 'PRODUCT NAME':\n",
                "            df.iloc[i+j,\n",
                "                        4] = tokenizer.decode(outputs[j], skip_special_tokens=True)\n",
                "    i += 5\n",
                "df = df[['searchKeyword', 'output']]\n",
                "print(df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "####PRA LEVEL CLASSIFICATION########\n",
                "pra = pd.read_csv('pra_list.csv')\n",
                "\n",
                "dic = {}\n",
                "cats = ''\n",
                "for i, j in enumerate(pra['pra_name_en']):\n",
                "    cats += f'option{i+1}: {j}, '\n",
                "    dic.update({str(i+1):j})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "###HFB LEVEL CLASSIFICATION#################\n",
                "\n",
                "cats = \"\"\"option1: Customer support, option2: Living room seating, option3: Store and organise furniture, option4: Workspaces, \n",
                "option5: Bedroom furniture, option6: Beds & Mattresses, option7: Bathroom, option8: Kitchen, option9: Dining, option10: Children´s IKEA, \n",
                "option11: Lighting, option12: Bed and bath textiles, option13: Home textiles, option14: Rugs, option15: Cooking, option16: Eating, \n",
                "option17: Decoration, option18: Outdoor & Secondary storage, option19: Home organisation, option20: Other business opportunities, \n",
                "option21: Home electronics, option22: Home Appliances\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cats = \"\"\"option1: product_type, option2: room, option3: service\"\"\"\n",
                "dic = {\"option1\": \"product_type\", \"option2\": \"room\", \"option3\": \"service\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Positive\n"
                    ]
                }
            ],
            "source": [
                "######DEFAULT CODE#############\n",
                "\n",
                "inputs = tokenizer.encode(\"Review: this is the best cast iron skillet you will ever buy. Is this review positive or negative?\", return_tensors=\"pt\")\n",
                "inputs = inputs.to(\"cuda:0\")\n",
                "with torch.no_grad():\n",
                "    outputs = model.generate(inputs)\n",
                "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0\n",
                        "1\n",
                        "2\n",
                        "3\n",
                        "4\n",
                        "5\n",
                        "6\n",
                        "7\n",
                        "8\n",
                        "9\n",
                        "10\n",
                        "11\n",
                        "12\n",
                        "13\n",
                        "14\n",
                        "15\n",
                        "16\n",
                        "17\n",
                        "18\n",
                        "19\n",
                        "20\n",
                        "21\n",
                        "22\n",
                        "23\n",
                        "24\n",
                        "25\n",
                        "26\n",
                        "27\n",
                        "28\n",
                        "29\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_17174/2557804695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m             )\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;31m# stop when each sentence is finished, or if we exceed the maximum length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0munfinished_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstopping_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msynced_gpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "######BATCH ENCODING#####\n",
                "df = pd.read_csv('top_queries_with_product.csv')\n",
                "i = 0\n",
                "while i<191:\n",
                "    inp = [f\"Query: {search}. Which category option does it belong to?\" + cats for search in df.iloc[i:i+50,1]]\n",
                "    inputs = tokenizer.batch_encode_plus(inp, return_tensors='pt', padding=True)\n",
                "    inputs = inputs.to(\"cuda:0\")\n",
                "    with torch.no_grad():\n",
                "        for j in range(len(inp)):\n",
                "            print(i+j)\n",
                "            outputs = model.generate(inputs['input_ids'])\n",
                "            df.iloc[i+j,4] = dic[tokenizer.decode(outputs[j], skip_special_tokens=True)]\n",
                "    i+=50\n",
                "df = df[['searchKeyword', 'output']]\n",
                "df.to_csv('full_cat_result.csv')\n",
                "print(\"FINISHED\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'option1': 'product_type', 'option2': 'room', 'option3': 'service'}"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'product_type'"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tokenizer.decode(outputs[j], skip_special_tokens=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ddf=df['pra_name_en'].reset_index(drop=True)\n",
                "ddf.to_csv('pra_list.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0       True\n",
                            "1      False\n",
                            "2       True\n",
                            "3       True\n",
                            "4      False\n",
                            "5       True\n",
                            "6       True\n",
                            "7       True\n",
                            "8       True\n",
                            "9       True\n",
                            "10      True\n",
                            "11     False\n",
                            "12      True\n",
                            "13      True\n",
                            "14      True\n",
                            "15      True\n",
                            "16      True\n",
                            "17      True\n",
                            "18      True\n",
                            "19      True\n",
                            "20     False\n",
                            "21      True\n",
                            "22      True\n",
                            "23     False\n",
                            "24      True\n",
                            "25      True\n",
                            "26      True\n",
                            "27      True\n",
                            "28      True\n",
                            "29      True\n",
                            "30      True\n",
                            "31      True\n",
                            "32      True\n",
                            "33      True\n",
                            "34      True\n",
                            "35      True\n",
                            "36      True\n",
                            "37      True\n",
                            "38      True\n",
                            "39      True\n",
                            "40      True\n",
                            "41      True\n",
                            "42      True\n",
                            "43      True\n",
                            "44      True\n",
                            "45      True\n",
                            "46      True\n",
                            "47      True\n",
                            "48      True\n",
                            "49      True\n",
                            "50      True\n",
                            "51      True\n",
                            "52      True\n",
                            "53      True\n",
                            "54      True\n",
                            "55      True\n",
                            "56      True\n",
                            "57      True\n",
                            "58      True\n",
                            "59      True\n",
                            "60      True\n",
                            "61      True\n",
                            "62      True\n",
                            "63      True\n",
                            "64      True\n",
                            "65      True\n",
                            "66      True\n",
                            "67      True\n",
                            "68      True\n",
                            "69      True\n",
                            "70      True\n",
                            "71      True\n",
                            "72      True\n",
                            "73      True\n",
                            "74      True\n",
                            "75      True\n",
                            "76      True\n",
                            "77     False\n",
                            "78     False\n",
                            "79      True\n",
                            "80      True\n",
                            "81      True\n",
                            "82      True\n",
                            "83      True\n",
                            "84      True\n",
                            "85      True\n",
                            "86      True\n",
                            "87      True\n",
                            "88      True\n",
                            "89      True\n",
                            "90      True\n",
                            "91      True\n",
                            "92      True\n",
                            "93      True\n",
                            "94      True\n",
                            "95      True\n",
                            "96      True\n",
                            "97      True\n",
                            "98      True\n",
                            "99      True\n",
                            "100     True\n",
                            "101     True\n",
                            "102     True\n",
                            "103     True\n",
                            "104     True\n",
                            "105     True\n",
                            "106     True\n",
                            "107    False\n",
                            "108     True\n",
                            "109     True\n",
                            "110     True\n",
                            "111     True\n",
                            "112     True\n",
                            "113     True\n",
                            "114     True\n",
                            "115     True\n",
                            "116     True\n",
                            "117     True\n",
                            "118    False\n",
                            "119     True\n",
                            "120    False\n",
                            "121     True\n",
                            "122     True\n",
                            "123     True\n",
                            "124     True\n",
                            "125     True\n",
                            "126     True\n",
                            "127    False\n",
                            "128     True\n",
                            "129     True\n",
                            "130     True\n",
                            "131     True\n",
                            "132     True\n",
                            "133     True\n",
                            "134     True\n",
                            "135     True\n",
                            "136     True\n",
                            "137     True\n",
                            "138     True\n",
                            "139     True\n",
                            "140     True\n",
                            "141     True\n",
                            "142     True\n",
                            "143     True\n",
                            "144     True\n",
                            "145     True\n",
                            "146     True\n",
                            "147     True\n",
                            "148     True\n",
                            "149     True\n",
                            "150     True\n",
                            "151     True\n",
                            "152     True\n",
                            "153     True\n",
                            "154    False\n",
                            "155     True\n",
                            "156     True\n",
                            "157     True\n",
                            "158     True\n",
                            "159     True\n",
                            "160    False\n",
                            "161     True\n",
                            "162     True\n",
                            "163    False\n",
                            "164    False\n",
                            "165     True\n",
                            "166     True\n",
                            "167    False\n",
                            "168     True\n",
                            "169    False\n",
                            "170     True\n",
                            "171     True\n",
                            "172     True\n",
                            "173     True\n",
                            "174     True\n",
                            "175     True\n",
                            "176     True\n",
                            "177    False\n",
                            "178     True\n",
                            "179    False\n",
                            "180     True\n",
                            "181    False\n",
                            "182     True\n",
                            "183     True\n",
                            "184     True\n",
                            "185     True\n",
                            "186    False\n",
                            "187     True\n",
                            "188     True\n",
                            "189     True\n",
                            "190     True\n",
                            "191     True\n",
                            "192    False\n",
                            "Name: pra_name_en, dtype: bool"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pra['pra_name_en'].isin(pra['pra_name_en'].iloc[l])==False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'tokenizer' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_17174/875023690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# inputs = tokenizer.batch_encode_plus(inp, return_tensors='pt', padding=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# inputs = inputs.to(\"cuda:0\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Query: {df['searchKeyword'].iloc[i]}. Which category does it belong to?\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv('top_queries_with_product.csv')\n",
                "i = 0\n",
                "while i<10000:\n",
                "    # inp = [f\"Query: {search}. Which category does it belong to?\" + cats for search in df.iloc[i:i+3,1]]\n",
                "    # inputs = tokenizer.batch_encode_plus(inp, return_tensors='pt', padding=True)\n",
                "    # inputs = inputs.to(\"cuda:0\")\n",
                "    inputs = tokenizer.encode(f\"Query: {df['searchKeyword'].iloc[i]}. Which category does it belong to?\" + cats, return_tensors=\"pt\")\n",
                "    inputs = inputs.to(\"cuda:0\")\n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(inputs)\n",
                "        #outputs = model.generate(inputs['input_ids'])\n",
                "    if df.iloc[i+j,4] != 'PRODUCT NAME':\n",
                "        df.iloc[i+j,4] = dic[tokenizer.decode(outputs[0], skip_special_tokens=True)]\n",
                "    # for j in range(len(inp)):\n",
                "    #     print(i+j)\n",
                "    #     if df.iloc[i+j,4] != 'PRODUCT NAME':\n",
                "    #         df.iloc[i+j,4] = dic[tokenizer.decode(outputs[j], skip_special_tokens=True)]\n",
                "    i+=1\n",
                "df = df[['searchKeyword', 'output']]\n",
                "df.to_csv('full_result.csv')\n",
                "print(\"FINISHED\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "l = tokenizer.encode('Query: wardrobe. Which category does it belong to?option1: Living room tables.., option2: Seating & Reclining Furniture, option3: Media solutions & accessories, option4: Flooring, option5: Mattresses, option6: Wardrobes., option7: Mirrors., option8: Storage, option9: Work seating, option10: Bathroom furniture, option11: Kitchen fronts, option12: Kitchen worktops, option13: Kitchen accessories, option14: Dining tables, option15: Dining stools and bar stools, option16: Window textiles, option17: Home textiles, option18: Play., option19: Cooking, option20: Lamps, option21: Light sources and accessories., option22: Quilts and pillows, option23: Cushions, throws and chairpads, option24: Bath textiles, option25: Functional rugs, option26: Kitchen tools, option27: Dining and serving, option28: Cutlery, option29: Coffee and tea., option30: Green decoration, option31: Wall decoration., option32: Decoration objects, option33: Outdoor parasols and accessories, option34: Clothes and shoes organisation, option35: Baby., option36: Safety, option37: Children´s Furniture, option38: Decoration, option39: Swedish Food Market, option40: Habitat, option41: Living room seating, option42: Armchairs, option43: Living room tables, option44: Workspaces, option45: Bedroom furniture, option46: Beds, option47: Chest of drawers, option48: Mirrors, option49: Work Surfaces, option50: Flooring., option51: Kitchen taps, sinks and sink accessories, option52: Kitchen appliances, option53: Dining seating, option54: Bed textiles, option55: Rugs., option56: Baby,, option57: Eating, option58: Outdoor lighting, option59: Bath textiles., option60: Fabrics and accessories, option61: Cooking and dining textiles, option62: Cookware, option63: Storing and washing, option64: Glassware, option65: Vases and flowers, option66: Home decoration, option67: Small storage., option68: Laundry, cleaning and sorting, option69: Transport and assembly range, option70: Children storage, option71: Play, option72: Baby, option73: Wall decoration, option74: Bathroom furniture & organisers, option75: Restaurant., option76: Other products., option77: Integrated lighting, option78: Light sources, option79: Sustainable life at home, option80: Safety and security, option81: Sofas, option82: Bistro, option83: Assembly & Installation, option84: Transportation & Handling, option85: Planning & Advice')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('_result.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df['searchKeyword']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.concat([df.iloc[:10], df.iloc[-10:]]).reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0                wardrobe\n",
                            "1                    desk\n",
                            "2                  kallax\n",
                            "3                  mirror\n",
                            "4        chest of drawers\n",
                            "5                    malm\n",
                            "6                    sofa\n",
                            "7           bedside table\n",
                            "8                 shelves\n",
                            "9                 drawers\n",
                            "10             kid's room\n",
                            "11               delivery\n",
                            "12     assemble furniture\n",
                            "13       customer support\n",
                            "14                returns\n",
                            "15            dining room\n",
                            "16                 closet\n",
                            "17               bathroom\n",
                            "18                  porch\n",
                            "19                balcony\n",
                            "Name: searchKeyword, dtype: object"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.to_csv('example.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "Forbidden",
                    "evalue": "403 POST https://bigquery.googleapis.com/bigquery/v2/projects/ingka-search-modelling-dev/jobs?prettyPrint=false: Access Denied: BigQuery BigQuery: Missing required OAuth scope. Need BigQuery or Cloud Platform read scope.\n\n(job ID: 0edfb49e-4366-4f5e-a823-78e97a5fb68d)\n\n                           -----Query Job SQL Follows-----                            \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:SELECT * FROM `ingka-search-modelling-dev.search_data.top_10k_queries` LIMIT 1000\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_25592/3979512811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFROM\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mingka\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodelling\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_10k_queries\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mLIMIT\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout)\u001b[0m\n\u001b[1;32m   2774\u001b[0m         \u001b[0mjob_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JobReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m         \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m         \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   3177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3179\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleCloudError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3181\u001b[0m             \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_for_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         )\n\u001b[1;32m    648\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             ):\n\u001b[0;32m--> 641\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             )\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/opt/conda/envs/tz/lib/python3.7/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/ingka-search-modelling-dev/jobs?prettyPrint=false: Access Denied: BigQuery BigQuery: Missing required OAuth scope. Need BigQuery or Cloud Platform read scope.\n\n(job ID: 0edfb49e-4366-4f5e-a823-78e97a5fb68d)\n\n                           -----Query Job SQL Follows-----                            \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:SELECT * FROM `ingka-search-modelling-dev.search_data.top_10k_queries` LIMIT 1000\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |"
                    ]
                }
            ],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3.7.12 ('z')",
=======
   "display_name": "Python 2.7.16 64-bit",
>>>>>>> 5726c68875dbf9326b3ce41cc55eadb16cf35c22
   "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "2.7.16"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
<<<<<<< HEAD
    "hash": "146e1d1b458fe2084fa64e5e1f61d8dc80cf176a66b2db74b494635d4cf7f021"
=======
    "hash": "beb4f305451b4835b36a63cb1c75e625a7251cf8d76b65be2f5856eee68cb551"
>>>>>>> 5726c68875dbf9326b3ce41cc55eadb16cf35c22
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}