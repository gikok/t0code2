{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tz/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from lib2to3.pgen2 import token\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from itertools import chain\n",
    "from typing import Optional, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from torch.nn.modules.sparse import Embedding\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.linear import Linear\n",
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from train import DataCollatorForMultipleChoice\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizerBase,\n",
    "    default_data_collator,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    AdamW,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.file_utils import PaddingStrategy\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"dataset_name\"] = \"miniprompts002.parquet.gzip\"\n",
    "args[\"eval_name\"] = \"miniprompts002_eval.parquet.gzip\"\n",
    "args[\"model_name_or_path\"] = \"bigscience/T0_3B\"\n",
    "args[\"output_dir\"] = \"/home/gikok/output\"\n",
    "args[\"num_train_epochs\"] = 1\n",
    "args[\"per_device_train_batch_size\"] = 16\n",
    "args[\"per_device_eval_batch_size\"] = 16\n",
    "args[\"freeze_encoder\"] = True\n",
    "args[\"learning_rate\"] = 1e30\n",
    "args[\"parallelize\"] = False\n",
    "args[\"seed\"] = 42\n",
    "args[\"pad_to_max_length\"] = False\n",
    "args[\"input_eos\"] = False\n",
    "args[\"target_max_length\"] = 256\n",
    "args[\"max_length\"] = 512\n",
    "args[\"num_warmup_steps\"] = 0\n",
    "args[\"debug\"] = False\n",
    "args[\"lr_scheduler_type\"] = \"linear\"\n",
    "args[\"num_shots\"] = None\n",
    "args[\"weight_decay\"] = 0.0\n",
    "args[\"gradient_checkpoint\"] = False\n",
    "args[\"gradient_accumulation_steps\"] = 1\n",
    "args[\"max_train_steps\"] = None\n",
    "\n",
    "\n",
    "def resample(model, layer, n_new):\n",
    "\n",
    "    new_tensor = list(model.named_parameters())[layer][1].detach().cpu()\n",
    "\n",
    "    for i in range(2048):\n",
    "        val, bin = np.histogram(new_tensor[:-n_new, i], 10000)\n",
    "        pdf = val / sum(val)\n",
    "        cdf = np.cumsum(pdf)\n",
    "        b = (bin[1:] + bin[:-1]) / 2\n",
    "        new_tensor[-n_new:, i] = torch.tensor(\n",
    "            np.interp(np.random.random(n_new), cdf, b)\n",
    "        )\n",
    "    data = list(model.named_parameters())[layer][1].data\n",
    "    data[:, :] = new_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/18/2022 16:53:20 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "10/18/2022 16:53:20 - WARNING - datasets.builder - Using custom data configuration data-11314387c41b991e\n",
      "10/18/2022 16:53:20 - WARNING - datasets.builder - Reusing dataset parquet (/home/gikok/.cache/huggingface/datasets/parquet/data-11314387c41b991e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "10/18/2022 16:53:20 - WARNING - datasets.builder - Using custom data configuration data-11314387c41b991e\n",
      "10/18/2022 16:53:20 - WARNING - datasets.builder - Reusing dataset parquet (/home/gikok/.cache/huggingface/datasets/parquet/data-11314387c41b991e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "loading configuration file https://huggingface.co/bigscience/T0_3B/resolve/main/config.json from cache at /home/gikok/.cache/huggingface/transformers/7b128e6b48089ae556964fea17b39635abd0124e77f8fa30267896af500a4d6d.a54ecffc6881ea8ae0af8a0dca40a7bcd51ccf51d434d2f7d0569844f6fb1c60\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"bigscience/T0_3B\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 5120,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 2048,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bigscience/T0_3B/resolve/main/pytorch_model.bin from cache at /home/gikok/.cache/huggingface/transformers/a80e28e34bce4ce1d72ae1fcbb46861412498adb5ab95928e3344ddfc5481524.d53f6a5f906212dee199edcde17c3c43695656c435962f2dc1636562577598bb\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at bigscience/T0_3B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bigscience/T0_3B/resolve/main/config.json from cache at /home/gikok/.cache/huggingface/transformers/7b128e6b48089ae556964fea17b39635abd0124e77f8fa30267896af500a4d6d.a54ecffc6881ea8ae0af8a0dca40a7bcd51ccf51d434d2f7d0569844f6fb1c60\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"bigscience/T0_3B\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 5120,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 2048,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bigscience/T0_3B/resolve/main/spiece.model from cache at /home/gikok/.cache/huggingface/transformers/d8c957338a9c967898a57f364d17f1fc0b7e514780dbdd99eb5a6306cf6d9ad4.d6f0605ae3d57070be74b4c12206072ab332922acff822e6b5458691dbda7551\n",
      "loading file https://huggingface.co/bigscience/T0_3B/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/bigscience/T0_3B/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bigscience/T0_3B/resolve/main/special_tokens_map.json from cache at /home/gikok/.cache/huggingface/transformers/303fbee39a17e96552ac07e02b70ba62ff0ad760609687e3a1b92b4ad2dff58c.c94798918c92ded6aeef2d2f0e666d2cc4145eca1aa6e1336fde07f2e13e2f46\n",
      "loading file https://huggingface.co/bigscience/T0_3B/resolve/main/tokenizer_config.json from cache at /home/gikok/.cache/huggingface/transformers/2c9b4442b8c3ca21f0457cbd7b8e4705058d02c93336a0450d020dafc2abb4d3.b1a2e3c152960fdc6b3d16520fa9f1591e2818d7dd66946c219e651f224894bf\n",
      "loading configuration file https://huggingface.co/bigscience/T0_3B/resolve/main/config.json from cache at /home/gikok/.cache/huggingface/transformers/7b128e6b48089ae556964fea17b39635abd0124e77f8fa30267896af500a4d6d.a54ecffc6881ea8ae0af8a0dca40a7bcd51ccf51d434d2f7d0569844f6fb1c60\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"bigscience/T0_3B\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 5120,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 2048,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bigscience/T0_3B/resolve/main/config.json from cache at /home/gikok/.cache/huggingface/transformers/7b128e6b48089ae556964fea17b39635abd0124e77f8fa30267896af500a4d6d.a54ecffc6881ea8ae0af8a0dca40a7bcd51ccf51d434d2f7d0569844f6fb1c60\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"bigscience/T0_3B\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 5120,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 2048,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "10/18/2022 16:54:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/gikok/.cache/huggingface/datasets/parquet/data-11314387c41b991e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b1b3f56a8b163228.arrow\n",
      "10/18/2022 16:54:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/gikok/.cache/huggingface/datasets/parquet/data-11314387c41b991e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-6d0bd5c8f8782ee9.arrow\n",
      "/opt/conda/envs/tz/lib/python3.7/site-packages/transformers/optimization.py:350: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "10/18/2022 16:54:04 - INFO - __main__ - ***** Running training *****\n",
      "10/18/2022 16:54:04 - INFO - __main__ -   Num training = 25600\n",
      "10/18/2022 16:54:04 - INFO - __main__ -   Num Epochs = 1\n",
      "10/18/2022 16:54:04 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
      "10/18/2022 16:54:04 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "10/18/2022 16:54:04 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "10/18/2022 16:54:04 - INFO - __main__ -   Total optimization steps = 1600\n",
      "  0%|          | 0/1600 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "set_seed(args[\"seed\"])\n",
    "\n",
    "# Initialize the accelerator. We will let the accelerator handle device placement for us.\n",
    "accelerator = Accelerator()\n",
    "# Make one log on every process with the configuration for debugging.\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.info(accelerator.state)\n",
    "\n",
    "# Setup logging, we only want one process per machine to log things on the screen.\n",
    "# accelerator.is_local_main_process is only True for one process per machine.\n",
    "logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "# Handle the output directory creation\n",
    "if accelerator.is_main_process:\n",
    "    os.makedirs(args[\"output_dir\"], exist_ok=True)\n",
    "accelerator.wait_for_everyone()\n",
    "\n",
    "# In distributed evaluation, the load_dataset function guarantee that only one local process can concurrently\n",
    "# download the dataset.\n",
    "if args[\"dataset_name\"] is not None:\n",
    "    data_files = {\"train\": args[\"dataset_name\"], \"test\": args[\"eval_name\"]}\n",
    "    raw_train_dataset = load_dataset(\"data\", data_files=data_files, split=\"train\")\n",
    "    raw_eval_dataset = load_dataset(\"data\", data_files=data_files, split=\"test\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Please specify `args['dataset_name`.\")\n",
    "\n",
    "# Trim a number of evaluation training\n",
    "if args[\"debug\"]:\n",
    "    raw_train_dataset = raw_train_dataset.select(\n",
    "        range(min(100, len(raw_train_dataset)))\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(args[\"model_name_or_path\"]).to(\"cuda:0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(args[\"model_name_or_path\"])\n",
    "\n",
    "# get all item_no and add as tokens\n",
    "items = pd.read_parquet(\"data/item_no_100.parquet.gzip\")[\"item_no\"].values.tolist()\n",
    "# tokenizer.add_tokens(items)\n",
    "\n",
    "# # then resize embeddings\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# # resample shared embedding and lm_head layer\n",
    "# resample(model, 0, len(items))\n",
    "# resample(model, -1, len(items))\n",
    "\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "# First we tokenize all the texts.\n",
    "padding = \"max_length\" if args[\"pad_to_max_length\"] else False\n",
    "\n",
    "\n",
    "def tokenize_train(examples):\n",
    "    input_texts = examples[\"input\"]\n",
    "    target_texts = examples[\"target\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        input_texts,\n",
    "        padding=padding,\n",
    "        max_length=args[\"max_length\"],\n",
    "        truncation=True,\n",
    "        add_special_tokens=args[\"input_eos\"],\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        tokenized_targets = tokenizer(\n",
    "            target_texts,\n",
    "            padding=padding,\n",
    "            max_length=args[\"target_max_length\"],\n",
    "            truncation=True,\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "        model_inputs[\"labels\"] = [\n",
    "            [(t if t != tokenizer.pad_token_id else -100) for t in targets]\n",
    "            for targets in tokenized_targets[\"input_ids\"]\n",
    "        ]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "column_names = raw_eval_dataset.column_names\n",
    "\n",
    "\n",
    "def preprocess_eval(examples):\n",
    "    input_texts = examples[\"input\"]\n",
    "    target_texts = examples[\"target\"]\n",
    "    answer_choices_texts = examples[\"options\"]\n",
    "    bs = len(examples[column_names[0]])\n",
    "\n",
    "    tokenized_inputs = tokenizer(\n",
    "        input_texts,\n",
    "        padding=padding,\n",
    "        max_length=args[\"max_length\"],\n",
    "        truncation=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    tokenized_targets = [\n",
    "        tokenizer(\n",
    "            ans_choi,\n",
    "            padding=padding,\n",
    "            max_length=args[\"target_max_length\"],\n",
    "            truncation=True,\n",
    "        )\n",
    "        for ans_choi in answer_choices_texts\n",
    "    ]\n",
    "\n",
    "    features = {\n",
    "        k: [\n",
    "            [elem for _ in range(len(tokenized_targets[idx][\"input_ids\"]))]\n",
    "            for idx, elem in enumerate(v)\n",
    "        ]\n",
    "        for k, v in tokenized_inputs.items()\n",
    "    }\n",
    "\n",
    "    features[\"labels\"] = [tokenized_targets[idx][\"input_ids\"] for idx in range(bs)]\n",
    "    features[\"labels_attention_mask\"] = [\n",
    "        tokenized_targets[idx][\"attention_mask\"] for idx in range(bs)\n",
    "    ]\n",
    "    features[\"targets\"] = [\n",
    "        answer_choices_texts[idx].index(t) for idx, t in enumerate(target_texts)\n",
    "    ]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "with accelerator.main_process_first():\n",
    "    eval_dataset = raw_eval_dataset.map(\n",
    "        preprocess_eval, batched=True, remove_columns=column_names\n",
    "    )\n",
    "\n",
    "    if args[\"num_shots\"] is not None:\n",
    "        sample_indices = random.sample(\n",
    "            range(0, len(raw_train_dataset)), k=args[\"num_shots\"]\n",
    "        )\n",
    "        raw_train_dataset = raw_train_dataset.select(sample_indices)\n",
    "    train_dataset = raw_train_dataset.map(tokenize_train, batched=True)\n",
    "    train_dataset.set_format(\n",
    "        type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# Log a few random training:\n",
    "for index in random.sample(range(len(train_dataset)), 3):\n",
    "    logger.debug(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "# for index in random.sample(range(len(eval_dataset)), 3):\n",
    "#     logger.debug(f\"Sample {index} of the evaluation set: {eval_dataset[index]}.\")\n",
    "\n",
    "# DataLoaders creation:\n",
    "train_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=8 if accelerator.use_fp16 else None,\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_collator,\n",
    "    batch_size=args[\"per_device_train_batch_size\"],\n",
    ")\n",
    "\n",
    "if args[\"pad_to_max_length\"]:\n",
    "    # If padding was already done ot max length, we use the default data collator that will just convert everything\n",
    "    # to tensors.\n",
    "    eval_collator = default_data_collator\n",
    "else:\n",
    "    # Otherwise, `DataCollatorWithPadding` will apply dynamic padding for us (by padding to the maximum length of\n",
    "    # the samples passed). When using mixed precision, we add `pad_to_multiple_of=8` to pad all tensors to multiple\n",
    "    # of 8s, which will enable the use of Tensor Cores on NVIDIA hardware with compute capability >= 7.5 (Volta).\n",
    "    eval_collator = DataCollatorForMultipleChoice(\n",
    "        tokenizer, pad_to_multiple_of=(8 if accelerator.use_fp16 else None)\n",
    "    )\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    collate_fn=eval_collator,\n",
    "    batch_size=args[\"per_device_eval_batch_size\"],\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": args[\"weight_decay\"],\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args[\"learning_rate\"])\n",
    "\n",
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = math.ceil(\n",
    "    len(train_dataloader) / args[\"gradient_accumulation_steps\"]\n",
    ")\n",
    "if args[\"max_train_steps\"] is None:\n",
    "    args[\"max_train_steps\"] = args[\"num_train_epochs\"] * num_update_steps_per_epoch\n",
    "else:\n",
    "    args[\"num_train_epochs\"] = math.ceil(\n",
    "        args[\"max_train_steps\"] / num_update_steps_per_epoch\n",
    "    )\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=args[\"lr_scheduler_type\"],\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args[\"num_warmup_steps\"],\n",
    "    num_training_steps=args[\"max_train_steps\"],\n",
    ")\n",
    "\n",
    "if args[\"parallelize\"]:\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    assert num_gpus > 1, \"You need at least 2 GPUs to use `model.parallelize()`.\"\n",
    "    model.parallelize()\n",
    "    optimizer, train_dataloader = accelerator.prepare(optimizer, train_dataloader)\n",
    "else:\n",
    "    model, optimizer, train_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader\n",
    "    )\n",
    "\n",
    "# Metrics\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "total_batch_size = (\n",
    "    args[\"per_device_train_batch_size\"]\n",
    "    * accelerator.num_processes\n",
    "    * args[\"gradient_accumulation_steps\"]\n",
    ")\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num training = {len(train_dataset)}\")\n",
    "logger.info(f\"  Num Epochs = {args['num_train_epochs']}\")\n",
    "logger.info(\n",
    "    f\"  Instantaneous batch size per device = {args['per_device_train_batch_size']}\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\"\n",
    ")\n",
    "logger.info(f\"  Gradient Accumulation steps = {args['gradient_accumulation_steps']}\")\n",
    "logger.info(f\"  Total optimization steps = {args['max_train_steps']}\")\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(\n",
    "    range(args[\"max_train_steps\"]), disable=not accelerator.is_local_main_process\n",
    ")\n",
    "global_steps = 0\n",
    "\n",
    "# how often trained model should be saved\n",
    "r = int(args[\"max_train_steps\"] / 30)\n",
    "if args[\"gradient_checkpoint\"]:\n",
    "    model.gradient_checkpointing_enable()\n",
    "model_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_grad = []\n",
    "em_delta_pct = []\n",
    "lm_grad = []\n",
    "lm_delta_pct = []\n",
    "em = list(model.named_parameters())[0][1]\n",
    "lm = list(model.named_parameters())[-1][1]\n",
    "em_old = em * 1\n",
    "lm_old = lm * 1\n",
    "init_len = len(tokenizer) - len(items)\n",
    "def hook(grad):\n",
    "    grad_mask[:init_len, :] = 0\n",
    "    return grad*grad_mask\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"encoder\") or name.startswith(\"decoder\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"shared\") or name.startswith(\"lm_head\"):\n",
    "        grad_mask = torch.ones_like(param)\n",
    "        grad_mask[:init_len, :] = 0\n",
    "        h = param.register_hook(hook)\n",
    "for epoch in range(1, 2):#args[\"num_train_epochs\"] + 1):\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        if step % 1 == 0 or step == len(train_dataloader) - 1:\n",
    "            item_no = int(step/4)\n",
    "            ind = len(tokenizer) - 100 + item_no\n",
    "            em_grad += [\n",
    "                ((em.grad[ind, :]).mean()).cpu()*1\n",
    "            ]\n",
    "            lm_grad += [\n",
    "                ((lm.grad[ind, :]).mean()).cpu()*1\n",
    "            ]\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            loss = loss.item()\n",
    "            em = list(model.named_parameters())[0][1]\n",
    "            lm = list(model.named_parameters())[-1][1]\n",
    "            em_delta_pct += [\n",
    "                (((em[ind, :] - em_old[ind, :]) / em[ind, :]).mean()).cpu()\n",
    "            ]\n",
    "            lm_delta_pct += [\n",
    "                (((lm[ind, :] - lm_old[ind, :]) / lm[ind, :]).mean()).cpu()\n",
    "            ]\n",
    "            em_old = em * 1\n",
    "            lm_old = lm * 1\n",
    "            if accelerator.is_main_process:\n",
    "                tqdm.write(f\"epoch = {epoch}, step = {global_steps}, loss = {loss}\")\n",
    "        if step >= 25:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_len = len(tokenizer) - len(items)\n",
    "def hook(grad):\n",
    "    grad_mask[:init_len, :] = 0\n",
    "    return grad*grad_mask\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"encoder\") or name.startswith(\"decoder\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"shared\") or name.startswith(\"lm_head\"):\n",
    "        grad_mask = torch.ones_like(param)\n",
    "        grad_mask[:init_len, :] = 0\n",
    "        h = param.register_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0476074218750000, -0.0622558593750000, -0.0976562500000000,\n",
       "         ...,  0.0262451171875000,  0.0427246093750000,\n",
       "        -0.0295410156250000], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = list(model.named_parameters())[-1][1]\n",
    "lm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0476074218750000, -0.0622558593750000, -0.0976562500000000,\n",
       "         ...,  0.0262451171875000,  0.0427246093750000,\n",
       "        -0.0295410156250000], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = list(model.named_parameters())[-1][1]\n",
    "lm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = lr\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        # Logging to TensorBoard by default\n",
    "        print(loss)\n",
    "        #self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.learning_rate)\n",
    "\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plmodel = LitAutoEncoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/18/2022 16:59:35 - INFO - pytorch_lightning.trainer.connectors.accelerator_connector - Auto select gpus: [0]\n",
      "10/18/2022 16:59:36 - INFO - pytorch_lightning.utilities.rank_zero - GPU available: True (cuda), used: True\n",
      "10/18/2022 16:59:36 - INFO - pytorch_lightning.utilities.rank_zero - TPU available: False, using: 0 TPU cores\n",
      "10/18/2022 16:59:36 - INFO - pytorch_lightning.utilities.rank_zero - IPU available: False, using: 0 IPUs\n",
      "10/18/2022 16:59:36 - INFO - pytorch_lightning.utilities.rank_zero - HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, auto_select_gpus=True, auto_lr_find=True, accumulate_grad_batches=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.fit(model=plmodel, train_dataloaders=train_dataloader)\n",
    "lr_finder = trainer.tuner.lr_find(model=plmodel, train_dataloaders=train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.786300923226385e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = lr_finder.plot(suggest=True)\n",
    "print(lr_finder.suggestion())\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"encoder\") or name.startswith(\"decoder\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"shared\") or name.startswith(\"lm_head\"):\n",
    "        t = torch.zeros(param.shape).to(\"cuda:0\")\n",
    "        t[-len(items) :, :] = 1\n",
    "        param.register_hook(lambda grad: grad * t)\n",
    "outputs = model(**batch)\n",
    "loss = outputs.loss\n",
    "accelerator.backward(loss)\n",
    "optimizer.step()\n",
    "lr_scheduler.step()\n",
    "optimizer.zero_grad()\n",
    "progress_bar.update(1)\n",
    "global_steps += 1\n",
    "loss = loss.item()\n",
    "if accelerator.is_main_process:\n",
    "    tqdm.write(f\"epoch = {1}, step = {global_steps}, loss = {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last(model.children())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_values[0][1].grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(np.zeros((new_values[0][1].shape[0], new_values[0][1].shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[-len(items) :, :] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "for mod in model.modules():\n",
    "    l += 1\n",
    "    if isinstance(mod, Embedding):\n",
    "        if mod.num_embeddings == 38136:\n",
    "            print(l, mod)\n",
    "            print(type(mod))\n",
    "            print(mod.num_embeddings)\n",
    "            print(\"****************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "for mod in model.modules():\n",
    "    print(mod)\n",
    "    print(\"**************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('api')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f85b80060f8df4254776023edad73a175582165cced4c0d1e12a1f8be9291edb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
