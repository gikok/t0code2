{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime as dt\n",
    "from IPython.display import display, HTML\n",
    "from datasets import load_dataset\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/gikok/code/ingka-search-modelling-dev-3a2a4f44d9c5.json'\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "query = \"\"\"\n",
    "# Retrieves all events with click actions (event_action = select_content),their queries, resulting products, and number of queries resulting in specific product\n",
    "# Retrieves all events with click actions (event_action = select_content),their queries, and resulting products for the first PLP\n",
    "\n",
    "WITH session_target AS (\n",
    "  SELECT\n",
    "    hit_sequence_number,\n",
    "    event_category,\n",
    "    event_action,\n",
    "    session_id,\n",
    "    page_url_query_parameter,\n",
    "    next_page_url,\n",
    "    SPLIT(REGEXP_EXTRACT(page_url_query_parameter, r'\\?q=(\\w.+)+'), '&')[SAFE_OFFSET(0)] AS clean_query,\n",
    "    ARRAY_REVERSE(SPLIT(next_page_url,'/'))[SAFE_OFFSET(0)] AS target_product,\n",
    "    ARRAY_REVERSE(SPLIT(ARRAY_REVERSE(SPLIT(next_page_url,'/'))[SAFE_OFFSET(0)], '-'))[SAFE_OFFSET(0)] AS target_product_id,\n",
    "  FROM\n",
    "    ingka-web-analytics-prod.web_data_v2.hits_events_and_pages\n",
    "  WHERE\n",
    "    ( date_hit BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 365 DAY) AND CURRENT_DATE()\n",
    "      AND website_market_short = 'gb'\n",
    "      AND event_category = 'engagement'\n",
    "      AND event_action = 'select_content'\n",
    "      AND page_url_query_parameter IS NOT NULL) \n",
    "      \n",
    "\n",
    ")\n",
    "SELECT distinct target_product_id FROM session_target\n",
    "  WHERE\n",
    "    clean_query IS NOT NULL\n",
    "    AND REGEXP_CONTAINS(target_product, r'[0-9A-Za-z]*[\\d]')--target_product_id NOT IN ('products', 'en', 'Site Exit', 'gallery', 'shoppingcart', 'latest', 'search', 'login') -- prevent the target_product to become one of these 'next_pages'\n",
    "\"\"\"\n",
    "n = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "query = \"\"\"\n",
    "# Retrieves all events with click actions (event_action = select_content),their queries, resulting products, and number of queries resulting in specific product\n",
    "# Retrieves all events with click actions (event_action = select_content),their queries, and resulting products for the first PLP\n",
    "\n",
    "WITH session_target AS (\n",
    "  SELECT\n",
    "    hit_sequence_number,\n",
    "    event_category,\n",
    "    event_action,\n",
    "    session_id,\n",
    "    page_url_query_parameter,\n",
    "    next_page_url,\n",
    "    SPLIT(REGEXP_EXTRACT(page_url_query_parameter, r'\\?q=(\\w.+)+'), '&')[SAFE_OFFSET(0)] AS clean_query,\n",
    "    ARRAY_REVERSE(SPLIT(next_page_url,'/'))[SAFE_OFFSET(0)] AS target_product,\n",
    "    ARRAY_REVERSE(SPLIT(ARRAY_REVERSE(SPLIT(next_page_url,'/'))[SAFE_OFFSET(0)], '-'))[SAFE_OFFSET(0)] AS target_product_id,\n",
    "  FROM\n",
    "    ingka-web-analytics-prod.web_data_v2.hits_events_and_pages\n",
    "  WHERE\n",
    "    ( date_hit BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 365 DAY) AND CURRENT_DATE()\n",
    "      AND website_market_short = 'gb'\n",
    "      AND event_category = 'engagement'\n",
    "      AND event_action = 'select_content'\n",
    "      AND page_url_query_parameter IS NOT NULL) \n",
    "\n",
    "),\n",
    "clean_query_product AS (\n",
    "  SELECT\n",
    "    session_id,\n",
    "    clean_query,\n",
    "    REGEXP_REPLACE(target_product, r'-', ' ') AS target_product,\n",
    "    target_product_id,\n",
    "    COUNT(*) AS query_n_resulting_product\n",
    "  FROM\n",
    "    session_target\n",
    "  WHERE\n",
    "    clean_query IS NOT NULL\n",
    "    AND REGEXP_CONTAINS(target_product, r'[0-9A-Za-z]*[\\d]')--target_product_id NOT IN ('products', 'en', 'Site Exit', 'gallery', 'shoppingcart', 'latest', 'search', 'login') -- prevent the target_product to become one of these 'next_pages'\n",
    "  GROUP BY\n",
    "    clean_query,\n",
    "    target_product_id,\n",
    "    target_product,\n",
    "    session_id\n",
    "  ORDER BY\n",
    "    clean_query\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  clean_query, \n",
    "  ARRAY_AGG(target_product_id IGNORE NULLS order by query_n_resulting_product desc) as term_frequency_ranking\n",
    "FROM clean_query_product \n",
    "GROUP BY clean_query\n",
    "\n",
    "\"\"\"\n",
    "r = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['rank_1'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[0]).zfill(8))\n",
    "r['rank_2'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[1]).zfill(8) if len(list(x))>1 else None)\n",
    "r['rank_3'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[2]).zfill(8) if len(list(x))>2 else None)\n",
    "r['rank_4'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[3]).zfill(8) if len(list(x))>3 else None)\n",
    "r['rank_5'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[4]).zfill(8) if len(list(x))>4 else None)\n",
    "r['rank_6'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[5]).zfill(8) if len(list(x))>5 else None)\n",
    "r['rank_7'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[6]).zfill(8) if len(list(x))>6 else None)\n",
    "r['rank_8'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[7]).zfill(8) if len(list(x))>7 else None)\n",
    "r['rank_9'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[8]).zfill(8) if len(list(x))>8 else None)\n",
    "r['rank_10'] = r['term_frequency_ranking'].apply(lambda x: re.sub(\"[^0-9]\", \"\",list(x)[9]).zfill(8) if len(list(x))>9 else None)\n",
    "r.drop(labels='term_frequency_ranking', axis=1, inplace=True)\n",
    "r['clean_query'] = r['clean_query'].apply(lambda x: x.replace('%20', ' '))\n",
    "r['clean_query'] = r['clean_query'].apply(lambda x: x.replace('+', ' '))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.to_hdf('year_queries.hdf5', index=False, key='year_queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('descriptions.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_no'] = df['id'].apply(lambda x: re.sub(\"[^0-9]\", \"\",x.split(\",\")[1]).zfill(8))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['item_no']+list(df.columns[1:-1])]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_hdf('all_en_descriptions.hdf5', key='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_hdf('filtered_GB_en_descriptions.hdf5', key='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = new_df.merge(f, how='inner', on='item_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xl/hlxf3zj95qg2j_1v665rbl6npf2gnr/T/ipykernel_37427/2492098744.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_no'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame({'item_no':[], 'input':[], 'target':[], 'options':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.append({'item_no':item_no, 'input':inp, 'target':target, 'options':opt}, ignore_index=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [no_to_name, name_to_no, is_description, is_summary, true_query, true_query, true_query, query_rank, query_rank]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "#queries = pd.read_hdf('year_queries.hdf5')\n",
    "#df = pd.read_hdf(\"filtered_GB_en_descriptions.hdf5\")\n",
    "functions = [no_to_name, name_to_no, is_description, is_summary, true_query, true_query, true_query, query_rank, query_rank]\n",
    "prompt_df = pd.DataFrame({'global_index':[],'item_no':[], 'input':[], 'target':[], 'options':[]})\n",
    "for i in range(len(df)):\n",
    "    start = time.time()\n",
    "    print('iteration: ', i)\n",
    "    index = i\n",
    "    item_no = df['item_no'].iloc[index]\n",
    "    query_df = queries[queries.isin([item_no]).any(axis=1)]\n",
    "    r = np.random.randint(0, 9, size=1024)\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    options = []\n",
    "    for j in range(1024):\n",
    "        f = functions[r[j]]\n",
    "        \n",
    "        if r[j] <4:\n",
    "            inp, tar, opt = f(index)\n",
    "            inputs += [inp]\n",
    "            targets += [tar]\n",
    "            options += [opt]\n",
    "        \n",
    "        else:\n",
    "            inp, tar, opt = f(query_df, item_no)\n",
    "            inputs += [inp]\n",
    "            targets += [tar]\n",
    "            options += [opt]\n",
    "        \n",
    "    prompt_df = prompt_df.append(pd.DataFrame({'global_index':list(np.arange(1024*i, 1024*(i+1))),'item_no':1024*[item_no], 'input':inputs, 'target':targets, 'options':options}), ignore_index=True)\n",
    "    print(f\"generating prompts for item_no {item_no} took {np.round(time.time()-start)} seconds.\")\n",
    "    print(\"\")\n",
    "    \n",
    "prompt_df.to_hdf('prompts.hdf5', key='alpha')\n",
    "prompt_df['insertion_time'] = dt.datetime.now()\n",
    "prompt_df['options'] = prompt_df['options'].apply(lambda x: str(x))\n",
    "prompt_df['global_index'] = prompt_df['global_index'].astype(int)\n",
    "prompt_df.to_gbq(destination_table = 'prompts.prompts_001', project_id='ingka-search-modelling-dev', if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('prompts.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_index</th>\n",
       "      <th>item_no</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10462236</td>\n",
       "      <td>if item_no is 10462236, which of the following...</td>\n",
       "      <td>hemlagad frying pan black</td>\n",
       "      <td>['hemlagad frying pan black',  'frasera whiske...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10462236</td>\n",
       "      <td>if name is hemlagad frying pan black, what ite...</td>\n",
       "      <td>10462236</td>\n",
       "      <td>['60435537',  '10462236',  '49454495']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10462236</td>\n",
       "      <td>query:'32cm fry pan'\\nthe query above returns ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 9, 5, 3, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10462236</td>\n",
       "      <td>if name is hemlagad frying pan black, what ite...</td>\n",
       "      <td>10462236</td>\n",
       "      <td>['20365094',  '39290701',  '40221047',  '10462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10462236</td>\n",
       "      <td>query:'hemlagad wok'\\nthe query above returns ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[10, 9, 3, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180859</th>\n",
       "      <td>6180859</td>\n",
       "      <td>99388356</td>\n",
       "      <td>no need to drill – just click on the handle wh...</td>\n",
       "      <td>no</td>\n",
       "      <td>[yes, no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180860</th>\n",
       "      <td>6180860</td>\n",
       "      <td>99388356</td>\n",
       "      <td>rug, low pile. is the previous sentence a summ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[yes, no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180861</th>\n",
       "      <td>6180861</td>\n",
       "      <td>99388356</td>\n",
       "      <td>storage combination. is the previous sentence ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[yes, no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180862</th>\n",
       "      <td>6180862</td>\n",
       "      <td>99388356</td>\n",
       "      <td>storage combination. is the previous sentence ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[yes, no]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180863</th>\n",
       "      <td>6180863</td>\n",
       "      <td>99388356</td>\n",
       "      <td>if item_no is 99388356, which of the following...</td>\n",
       "      <td>danderyd dining table oak veneer white</td>\n",
       "      <td>['danderyd dining table oak veneer white',  'l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6180864 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         global_index   item_no  \\\n",
       "0                   0  10462236   \n",
       "1                   1  10462236   \n",
       "2                   2  10462236   \n",
       "3                   3  10462236   \n",
       "4                   4  10462236   \n",
       "...               ...       ...   \n",
       "6180859       6180859  99388356   \n",
       "6180860       6180860  99388356   \n",
       "6180861       6180861  99388356   \n",
       "6180862       6180862  99388356   \n",
       "6180863       6180863  99388356   \n",
       "\n",
       "                                                     input  \\\n",
       "0        if item_no is 10462236, which of the following...   \n",
       "1        if name is hemlagad frying pan black, what ite...   \n",
       "2        query:'32cm fry pan'\\nthe query above returns ...   \n",
       "3        if name is hemlagad frying pan black, what ite...   \n",
       "4        query:'hemlagad wok'\\nthe query above returns ...   \n",
       "...                                                    ...   \n",
       "6180859  no need to drill – just click on the handle wh...   \n",
       "6180860  rug, low pile. is the previous sentence a summ...   \n",
       "6180861  storage combination. is the previous sentence ...   \n",
       "6180862  storage combination. is the previous sentence ...   \n",
       "6180863  if item_no is 99388356, which of the following...   \n",
       "\n",
       "                                         target  \\\n",
       "0                     hemlagad frying pan black   \n",
       "1                                      10462236   \n",
       "2                                             2   \n",
       "3                                      10462236   \n",
       "4                                             3   \n",
       "...                                         ...   \n",
       "6180859                                      no   \n",
       "6180860                                      no   \n",
       "6180861                                     yes   \n",
       "6180862                                     yes   \n",
       "6180863  danderyd dining table oak veneer white   \n",
       "\n",
       "                                                   options  \n",
       "0        ['hemlagad frying pan black',  'frasera whiske...  \n",
       "1                   ['60435537',  '10462236',  '49454495']  \n",
       "2                                         [2, 9, 5, 3, 10]  \n",
       "3        ['20365094',  '39290701',  '40221047',  '10462...  \n",
       "4                                            [10, 9, 3, 7]  \n",
       "...                                                    ...  \n",
       "6180859                                          [yes, no]  \n",
       "6180860                                          [yes, no]  \n",
       "6180861                                          [yes, no]  \n",
       "6180862                                          [yes, no]  \n",
       "6180863  ['danderyd dining table oak veneer white',  'l...  \n",
       "\n",
       "[6180864 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('df.parquet.gzip',\n",
    "              compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df.parquet.gzip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xl/hlxf3zj95qg2j_1v665rbl6npf2gnr/T/ipykernel_37427/330609352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df.parquet.gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     )\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         handles = get_handle(\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df.parquet.gzip'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('df.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"../data/filtered_GB_en_descriptions.hdf5\")\n",
    "d = df['item_no'].drop_duplicates().reset_index(drop=True)\n",
    "pd.DataFrame(d).to_parquet('../data/item_no_6k.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration .-7e90710a90d454b2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/. to /Users/gikok/.cache/huggingface/datasets/parquet/.-7e90710a90d454b2/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cf29b458c6472ba2b7770e3b48a477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e37acc70e04c3695c90d5a1c2db241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/gikok/.cache/huggingface/datasets/parquet/.-7e90710a90d454b2/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95dada1259464c26adc18271f2a41809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('.', data_files='df.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xl/hlxf3zj95qg2j_1v665rbl6npf2gnr/T/ipykernel_37427/2331531665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'options'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2123\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m         return self._getitem(\n\u001b[0;32m-> 2125\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2126\u001b[0m         )\n\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2109\u001b[0m         formatted_output = format_table(\n\u001b[0;32m-> 2110\u001b[0;31m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m         )\n\u001b[1;32m   2112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatted_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mextract_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pylist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b69ab5e747d4711a2b2361fc78ed149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6181 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if item_no is 10462236, which of the following is the correct name: 'hemlagad frying pan black' or 'frasera whiskey glass'?\n",
      "[\"'hemlagad frying pan black'\", \" 'frasera whiskey glass'\"]\n",
      "<class 'list'> 1000\n",
      "lol\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Provided `function` which is applied to all elements of table returns a variable of type <class 'list'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xl/hlxf3zj95qg2j_1v665rbl6npf2gnr/T/ipykernel_37427/2893043297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m train_dataset = data.map(\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtokenize_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 )\n\u001b[0;32m--> 790\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m             }\n\u001b[1;32m    792\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 )\n\u001b[0;32m--> 790\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m             }\n\u001b[1;32m    792\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2362\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2364\u001b[0;31m                 \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2365\u001b[0m             )\n\u001b[1;32m   2366\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         }\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2736\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m                                 \u001b[0mcheck_same_num_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2738\u001b[0;31m                                 \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2739\u001b[0m                             )\n\u001b[1;32m   2740\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mNumExamplesMismatchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2616\u001b[0m                 \u001b[0;31m# Check if the function returns updated examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m                 \u001b[0mupdate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m                 \u001b[0mvalidate_function_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Nothing to update, let's move on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/api/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mvalidate_function_output\u001b[0;34m(processed_inputs, indices)\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprocessed_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2588\u001b[0m                 raise TypeError(\n\u001b[0;32m-> 2589\u001b[0;31m                     \u001b[0;34mf\"Provided `function` which is applied to all elements of table returns a variable of type {type(processed_inputs)}. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2590\u001b[0m                 )\n\u001b[1;32m   2591\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Provided `function` which is applied to all elements of table returns a variable of type <class 'list'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects."
     ]
    }
   ],
   "source": [
    "def tokenize_train(examples):\n",
    "    input_texts = examples['input']\n",
    "    target_texts = examples['target']\n",
    "    opts = examples['options']\n",
    "    print(input_texts[0])\n",
    "    print(type(input_texts), len(input_texts))\n",
    "    print(\"lol\")\n",
    "    return input_texts\n",
    "train_dataset = data.map(\n",
    "    tokenize_train, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "inp, target, opt = no_to_name(index)\n",
    "item_no = df['item_no'].iloc[0]\n",
    "print(\"################# PROMPT TYPE 1 ########################\")\n",
    "print(\"INPUT:\",inp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"TARGET:\", target)\n",
    "inp, target, opt = name_to_no(index)\n",
    "print(\"################# PROMPT TYPE 2 ########################\")\n",
    "print(\"INPUT:\",inp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"TARGET:\", target)\n",
    "inp, target, opt = is_description(index)\n",
    "print(\"################# PROMPT TYPE 3 ########################\")\n",
    "print(\"INPUT:\",inp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"TARGET:\", target)\n",
    "inp, target, opt = is_summary(index)\n",
    "print(\"################# PROMPT TYPE 4 ########################\")\n",
    "print(\"INPUT:\",inp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"TARGET:\", target)   \n",
    "# get queries that have item_no\n",
    "query_df = queries[queries.isin([item_no]).any(axis=1)]\n",
    "inp, target, opt = true_query(query_df, item_no)\n",
    "print(\"################# PROMPT TYPE 5 ########################\")\n",
    "print(\"INPUT:\",inp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"TARGET:\", target)\n",
    "inp, target, opt = query_rank(query_df, item_no)\n",
    "print(\"################# PROMPT TYPE 6 ########################\")\n",
    "print(\"INPUT:\",inp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"TARGET:\", target)\n",
    "end = time.time()\n",
    "print(f\"It took {(end-start)*1e3} ms to generate prompts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.arange(3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n[n['item_no']=='00248567']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or(s):\n",
    "    li = s.rsplit(', ')\n",
    "    start = ', '.join(li[:-1])\n",
    "    end =  ' or ' + li[-1]\n",
    "    return start+end\n",
    "    \n",
    "\n",
    "def create_option_string(df, column, inds):\n",
    "    options = \"\"\n",
    "    for i in inds:\n",
    "        options +=  f\"'{df[column].iloc[i]}', \"\n",
    "        if i == inds[-1]:\n",
    "            options = options[:-2]\n",
    "            \n",
    "    option_string = add_or(options)\n",
    "    option_list = options.split(',')\n",
    "        \n",
    "    return option_string, option_list\n",
    "\n",
    "def get_other_indices(index, size, num):\n",
    "    \"\"\"\n",
    "    given a number {index}, returns {num} integers in range({size})\n",
    "    \"\"\"\n",
    "    \n",
    "    proceed = 0\n",
    "    while proceed == 0:\n",
    "        inds = np.random.choice(range(size), num)\n",
    "        # check if any of the new indices is same as initial\n",
    "        if (inds == index).any()==False:\n",
    "            proceed = 1\n",
    "        else:\n",
    "            proceed = 0\n",
    "    \n",
    "    return inds\n",
    "\n",
    "\n",
    "def no_to_name(index):\n",
    "    \n",
    "    # get random number of options\n",
    "    num = np.random.randint(1, 4)\n",
    "    \n",
    "    # get random item index\n",
    "    inds = get_other_indices(index, len(df), num)\n",
    "    inds = np.append(inds, index)\n",
    "    np.random.shuffle(inds)\n",
    "    \n",
    "    # get answer options\n",
    "    options, option_list = create_option_string(df, 'name', inds)\n",
    "    \n",
    "    # create the input string\n",
    "    inp = f\"if item_no is {df['item_no'].iloc[index]}, which of the following is the correct name: \" + options + '?'\n",
    "    \n",
    "    \n",
    "    # set the target\n",
    "    target = df['name'].iloc[inds[np.argmin(inds-index)]]\n",
    "    \n",
    "    return inp.lower(), target.lower(), option_list\n",
    "\n",
    "def name_to_no(index):\n",
    "    \n",
    "    # get random number of options\n",
    "    num = np.random.randint(1, 4)\n",
    "    \n",
    "    # get random item index\n",
    "    inds = get_other_indices(index, len(df), num)\n",
    "    inds = np.append(inds, index)\n",
    "    np.random.shuffle(inds)\n",
    "    \n",
    "    # get answer options\n",
    "    options, option_list = create_option_string(df, 'item_no', inds)\n",
    "    \n",
    "    # get the input string\n",
    "    inp = f\"if name is {df['name'].iloc[index]}, what item_no does it refer to? \" + options + '?' \n",
    "    \n",
    "    # get the target\n",
    "    target = df['item_no'].iloc[inds[np.argmin(inds-index)]]\n",
    "    \n",
    "    return inp.lower(), target.lower(), option_list\n",
    "\n",
    "def is_description(index):\n",
    "    \n",
    "    is_true = np.random.randint(2)\n",
    "    \n",
    "    if is_true:\n",
    "        desc = df['benefits'].iloc[index]\n",
    "        target = \"yes\"\n",
    "    else:\n",
    "        tempdf = df[df['benefits']!=df['benefits'].iloc[index]]\n",
    "        desc = np.random.choice(tempdf['benefits'])\n",
    "        target = \"no\"\n",
    "        \n",
    "    # make sure ends with period    \n",
    "    desc = desc if desc.endswith(\".\") else desc + \".\"\n",
    "    \n",
    "    # create input\n",
    "    inp = desc + f\" is the previous sentence a description of item_no {df['item_no'].iloc[index]}. yes or no?\"\n",
    "    \n",
    "    return inp.lower(), target, ['yes', 'no']\n",
    "\n",
    "def is_summary(index):\n",
    "    \n",
    "    is_true = np.random.randint(2)\n",
    "    \n",
    "    if is_true:\n",
    "        desc = df['key_w'].iloc[index]\n",
    "        target = \"yes\"\n",
    "    else:\n",
    "        tempdf = df[df['key_w']!=df['key_w'].iloc[index]]\n",
    "        desc = np.random.choice(tempdf['key_w'])\n",
    "        target = \"no\"\n",
    "        \n",
    "    # make sure ends with period    \n",
    "    desc = desc if desc.endswith(\".\") else desc + \".\"\n",
    "    \n",
    "    # create input\n",
    "    inp = desc + f\" is the previous sentence a summary of item_no {df['item_no'].iloc[index]}. yes or no?\"\n",
    "    \n",
    "    return inp.lower(), target, ['yes', 'no']\n",
    "\n",
    "def true_query(query_df, item_no):\n",
    "    \n",
    "    is_true = np.random.randint(2)\n",
    "    \n",
    "    if is_true:\n",
    "        query = query_df['clean_query'].sample().iloc[0]\n",
    "        target = \"yes\"\n",
    "    else:\n",
    "        query = query_df['clean_query'].sample().iloc[0]\n",
    "        target = \"no\"\n",
    "\n",
    "    \n",
    "    # create input\n",
    "    inp = \"query:'\" + query + f\"'\\ndoes the query above return item_no {item_no} as a result. yes or no?\"\n",
    "    \n",
    "    return inp.lower(), target, ['yes', 'no']\n",
    "\n",
    "def query_rank(query_df, item_no):\n",
    "\n",
    "    # select random row\n",
    "    row = query_df.sample()\n",
    "    \n",
    "    # get query string\n",
    "    query = row['clean_query'].iloc[0]\n",
    "    \n",
    "    # get rank of item_no\n",
    "    cols = np.array(row.columns)\n",
    "    inds = (row[row==item_no].isnull()==False).values[0]\n",
    "    \n",
    "    # get first true value, that is not 0 (queries can be for item_no) and\n",
    "    # sometimes same item_no has multiple ranks\n",
    "    if len(inds)>1:\n",
    "        inds[0] = False\n",
    "        rank = cols[np.argmax(inds)][-1]\n",
    "        \n",
    "        # if doesn't work keep trying\n",
    "        c = 0\n",
    "        while rank.isdigit()==False:\n",
    "            row = query_df.sample()\n",
    "            inds = (row[row==item_no].isnull()==False).values[0]\n",
    "            inds[0] = False\n",
    "            rank = cols[np.argmax(inds)][-1]\n",
    "            c +=1\n",
    "            if c>100:\n",
    "                print(f'stuck in infinite loop with item_no {item_no}')\n",
    "                break\n",
    "            \n",
    "    \n",
    "    # in case rank is 10\n",
    "    rank = '10' if rank=='0' else rank\n",
    "    \n",
    "    # create possible options\n",
    "    n_options = np.random.randint(1, 5)\n",
    "    \n",
    "    options = list(np.arange(1, 11))\n",
    "    options.remove(int(rank))\n",
    "    \n",
    "    options = np.append(np.random.choice(options, n_options).astype(str), rank)\n",
    "    np.random.shuffle(options)\n",
    "    \n",
    "    # create input\n",
    "    inp = \"query:'\" + query + f\"'\\nthe query above returns item_no {item_no} as a result. what is its rank? \" + add_or(', '.join(options))\n",
    "    \n",
    "    target = rank\n",
    "    return inp.lower(), target, list(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = '1'\n",
    "l.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels = 'term_frequency_ranking', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n['item_no'] = n['target_product_id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n['item_no'] = n['target_product_id'].apply(lambda x: re.sub(\"[^0-9]\", \"\",str(x)).zfill(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['item_no'] = pd.unique(queries[queries.columns[1:]].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.apply({'test':'test', 'testtest':\"testtest\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset = load_dataset('super_glue', 'cb', split='train')\n",
    "prompts = DatasetTemplates('super_glue', \"cb\")\n",
    "template = prompts['consider always/sometimes/never']\n",
    "\n",
    "column_names = raw_train_dataset.column_names\n",
    "def preprocess_train(examples):\n",
    "    bs = len(examples[column_names[0]])\n",
    "\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    answer_choices_texts = []\n",
    "    for i in range(10):\n",
    "        ex = {\n",
    "            k: examples[k][i]\n",
    "            for k in column_names\n",
    "        }\n",
    "        input, target = template.apply(ex)\n",
    "        ex_answer_choices = template.get_answer_choices_list(ex)\n",
    "        assert target in ex_answer_choices\n",
    "        input_texts.append(input)\n",
    "        target_texts.append(target)\n",
    "        answer_choices_texts.append(ex_answer_choices)\n",
    "    return input_texts, target_texts, answer_choices_texts\n",
    "\n",
    "i, t, a = preprocess_train(raw_train_dataset)\n",
    "for j in range(10):\n",
    "    print(\"%r\"%i[j])\n",
    "    print(\"%r\"%t[j])\n",
    "    print(\"%r\"%a[j])\n",
    "    print(\"********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get queries that have item_no\n",
    "qs = queries[queries.isin([item_no]).any(axis=1)]\n",
    "\n",
    "# select random row\n",
    "row = qs.sample()\n",
    "\n",
    "# get query string\n",
    "query = queries['clean_query']\n",
    "\n",
    "# get rank of item_no\n",
    "cols = np.array(row.columns)\n",
    "inds = (row[row==item_no].isnull()==False).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_no"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
